---
title: "Регрессионный анализ, часть 2"
subtitle: "Математические методы в зоологии с использованием R"
author: "Марина Варфоломеева"
classoption: 't,xcolor=table'
language: russian, english
output:
  beamer_presentation:
    colortheme: seagull
    highlight: tango
    fonttheme: structurebold
    latex_engine: xelatex
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - -V fontsize=10pt
    slide_level: 2
    fig_crop: false
    theme: CambridgeUS
    toc: no
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
options(width = 70, scipen = 6)
library(knitr)
opts_chunk$set(fig.show='hold', size='footnotesize', comment="#", warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7)
source("support_mathmethr.R")
```


### Вы сможете

- Подобрать модель множественной линейной регрессии
- Протестировать значимость модели и ее коэффициентов
- Интерпретировать коэффициенты множественной регрессии при разных предикторах
- Проверить условия применимости простой и множественной линейной регрессии при помощи анализа остатков

# Множественная линейная регрессия

## Пример: птицы Австралии

Зависит ли обилие птиц в лесах Австралии от характеристик леса? (Loyn, 1987, пример из кн. Quinn, Keough, 2002)

56 лесных участков в юго-восточной Виктории, Австралия

- `l10area` - Площадь леса, га (логарифм)
- `l10dist` - Расстояние до ближайшего леса, км (логарифм)
- `l10ldist` - Расстояние до ближайшего леса большего размера, км (логарифм)
- `yr.isol` - Год начала изоляции
- `abund` - Обилие птиц

## Читаем данные из файла одним из способов

### Чтение из xlsx
```{r}
library(readxl)
bird <- read_excel(path = "data/loyn.xlsx", sheet = 1)
```

### Чтение из csv

```{r}
bird <- read.table("data/loyn.csv", header = TRUE, sep = "\t")
```

## Все ли правильно открылось?

```{r}
str(bird)      # Структура данных
head(bird)     # Первые несколько строк файла
```

## Знакомимся с данными

Есть ли пропущенные значения?

```{r}
colSums(is.na(bird))
```

Каков объем выборки?

```{r}
nrow(bird)
```


## Задача

- Подберите модель множественной линейной регрессии, чтобы описать, как зависит обилие птиц от характеристик леса
- Проверьте значимость ее коэффициентов при помощи t-критерия

\vfill
Предикторы:

- `abund` - Обилие птиц
- `l10area` - Площадь леса, га
- `l10dist` - Расстояние до ближайшего леса, км (логарифм)
- `l10ldist` - Расстояние до ближайшего леса большего размера,
км (логарифм)
- `yr.isol` - Год изоляции лесного массива

## Решение

\fontsize{10pt}{10pt}
```{r purl=FALSE}
bird_lm <- lm(abund ~ l10area + l10dist + l10ldist + yr.isol, data = bird)
summary(bird_lm)
```

## Можно привести  результаты t-теста для коэффициентов в виде таблицы

Обилие птиц увеличивалось с увеличением площади леса, и с уменьшением продолжительности изоляции (Табл. \autoref{tab:mreg-coef}).

```{r echo=FALSE, results='asis', purl=FALSE}
library(xtable)
library(tidyr)
smr <- coef(summary(bird_lm)) %>% data.frame() %>% round(., 2)
# %>% format.data.frame(., digits = 2, nsmall = 1)
smr$Pr...t.. <- format.pval(smr$Pr...t.., eps = 0.01)
rownames(smr)[1] <- "Отрезок"
colnames(smr) <- c("Оценка", "Ст.ошибка", "t", "P")

xtb <- xtable(
  smr,
  caption = "Коэффициенты линейной регрессии обилия птиц от различных характеристик леса: l10area - логарифм площади леса, l10dist --- логарифм расстояния до ближайшего леса, l10ldist --- логарифм расстояния до ближайшего большого леса, yr.isol --- год изоляции лесного массива. t --- значение t-критерия, P --- уровень значимости.",
  label = "tab:mreg-coef")

print.xtable(xtb, comment = F, caption.placement = "top")
```

Можно было бы нарисовать график предсказаний модели, но в этом курсе мы не будем это разбирать

## Задача

Запишите уравнение множественной линейной регрессии

## Решение

Коэффициенты модели:

```{r purl=FALSE}
coef(bird_lm)
```

Уравнение регрессии:  

```{r results='asis', echo=FALSE, purl=FALSE}
lm_equation(bird_lm, strict=FALSE)
```

Более формальная запись:  

```{r results='asis', echo=FALSE, purl=FALSE}
lm_equation(bird_lm)
```

## Интерпретация коэффициентов регрессии

```{r}
coef(bird_lm)
```

\pause

### Обычные коэффициенты

- Величина обычных коэффициентов зависит от единиц измерения
- $b_0$ --- Отрезок (Intercept), отсекаемый регрессионной прямой на оси $y$. Значение зависимой переменной $Y$, если предикторы равны нулю.
- Коэффициенты при предикторах показывают, на сколько изменяется $Y$, когда данный предиктор меняется на единицу, при условии, что остальные предикторы не меняют своих значений.

## Для сравнения влияния разных предикторов --- стандартизованные коэффициенты

\fontsize{10pt}{10pt}

```{r}
scaled_bird_lm <- lm(abund ~ scale(l10area) + scale(l10dist) + 
                       scale(l10ldist) + scale(yr.isol), data = bird)
coef(scaled_bird_lm)
```

\pause

### Стандартизованные коэффициенты

- Стандартизованные коэффициенты измерены в стандартных отклонениях. Их можно сравнивать друг с другом, поскольку они дают относительную оценку влияния фактора.
- $b_0$ --- Отрезок (Intercept), отсекаемый регрессионной прямой на оси $y$. Значение зависимой переменной $Y$, если предикторы равны нулю. Для стандартизованных величин среднее значение равно нулю, поэтому $b_0$ --- это значение зависимой переменной при средних значениях всех предикторов.
- Коэффициенты при предикторах показывают, на сколько изменяется $Y$, когда предиктор меняется на одно стандартное отклонение, при условии, что остальные предикторы не меняют своих значений. Это относительная оценка влияния фактора.

## Задача

Определите по значениям стандартизованных коэффициентов, какие факторы сильнее всего влияют на обилие птиц

\fontsize{10pt}{10pt}

```{r}
summary(scaled_bird_lm)
```

## Оценка качества подгонки модели

```{r}
summary(bird_lm)$adj.r.squared
```

### Обычный $R^2$ --- доля объясненной изменчивости

$$R^2 =\frac{SS_{r}}{SS_{t}} = 1 - \frac{SS_{e}}{SS_{t}}$$

__Не используйте обычный $R^2$ для множественной регрессии!__

### $R^2_{adj}$ --- cкорректированный $R^2$

$$R^2_{adj} = 1 - (1 - R^2) \frac{n - 1}{n - p}$$

где $n - p = df_{e}$, $n - 1 = df_{t}$

$R^2_{adj}$ учитывает число переменных в модели, вводится штраф за каждый новый параметр.

Используйте $R^2 _{adj}$ для сравнения моделей с разным числом параметров.

# Условия применимости линейной регрессии

## Условия применимости линейной регрессии 

Условия применимости линейной регрессии должны выполняться, чтобы тестировать гипотезы

1. Независимость
1. Линейность 
1. Нормальное распределение
1. Гомогенность дисперсий
1. Отсутствие коллинеарности предикторов (для множественной регрессии)

## 1. Независимость


- Значения $y _i$ должны быть независимы друг от друга
- Берегитесь псевдоповторностей и автокорреляций (например, временных)
- Контролируется на этапе планирования
- Проверяем на графике остатков

\vskip0pt plus 1filll
\centering
\includegraphics[width=0.85\linewidth,keepaspectratio]{images/assumption-12.png}

\raggedright
\tiny Из кн. Diez et al., 2010, стр. 332, рис. 7.8

## 2. Линейность связи

- Проверяем на графике рассеяния исходных данных
- Проверяем на графике остатков

\vskip0pt plus 1filll
\centering
\includegraphics[width=0.85\linewidth,keepaspectratio]{images/assumption-12.png}

\raggedright
\tiny Из кн. Diez et al., 2010, стр. 332, рис. 7.8

## Что бывает, если не глядя применять линейную регрессию

\columnsbegin
\column{0.48\textwidth}

\href{http://ru.wikipedia.org/wiki/Квартет_Энскомба}{Квартет Энскомба} - примеры данных, где регрессии одинаковы во всех случаях (Anscombe, 1973)

\[y _i = 3.0 + 0.5 x _i\]

\[r^2 = 0.68\]

\[H _0: \beta _1 = 0, t = 4.24, p = 0.002\]


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/anscombe.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 97, рис. 5.9


\columnsend

## 3. Нормальное распределение остатков

\columnsbegin
\column{0.48\textwidth}
Нужно, т.к. в модели $Y _i = \beta _0 + \beta x _i + \epsilon _i$ зависимая переменная $Y \sim N(0,\sigma^2)$, а значит $\epsilon _i \sim N(0,\sigma^2)$

- Нужно для тестов параметров, а не для подбора методом наименьших квадратов
- Нарушение не страшно --- тесты устойчивы к небольшим отклонениям от нормального распределения
- Проверяем распределение остатков на нормально-вероятностном графике


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/normality-assumption.png}

\raggedright
\tiny Из кн. Watkins et al., 2008, стр. 743, рис. 11.4

\columnsend

## 4. Гомогенность дисперсий

\columnsbegin
\column{0.48\textwidth}
Нужно, т.к. в модели $Y _i = \beta _0 + \beta x _i + \epsilon _i$ зависимая переменная $Y \sim N(0,\sigma^2)$ и дисперсии $\sigma^2 _1 = \sigma^2 _2 = ... = \sigma^2 _i$ для каждого $Y _i$ \par
Но, поскольку $\epsilon _i \sim N(0,\sigma^2)$, можно проверить равенство дисперсий остатков $\epsilon _i$

- Нужно и важно для тестов параметров
- Проверяем на графике остатков по отношению к предсказанным значениям
- Есть формальные тесты, но они очень чувствительны (тест Бройша-Пагана, тест Кокрана)


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/normality-assumption.png}

\raggedright
\tiny Из кн. Watkins et al., 2008, стр. 743, рис. 11.4


\columnsend

## Диагностика регрессии по графикам остатков

\columnsbegin
\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-violations-on-residual-plots.png}

\raggedright
\tiny Из кн. Logan, 2010, стр. 174, рис. 8.5 d


\column{0.48\textwidth}

- (a)все условия выполнены  
- (b)разброс остатков разный (wedge-shaped pattern)  
- (c)разброс остатков одинаковый, но нужны дополнительные предикторы  
- (d)к нелинейной зависимости применили линейную регрессию  

\columnsend

## Задача: Проанализируйте графики остатков

Скажите пожалуйста


- какой регрессии соответствует какой график остатков?
- все ли условия применимости регрессии здесь выполняются?
- назовите случаи, в которых можно и нельзя применить линейную регрессию?

\columnsbegin
\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz1.png}

\column{0.48\textwidth}
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz2.png}

\columnsend

\tiny{Из кн. Watkins et al. 2008, стр. 177, рис. 3.84-3.85}


## Решение

- A-I - нелинейная связь - нельзя; 
- B-II - все в порядке, можно; 
- C-III - все в порядке, можно; 
- D-IV - синусоидальный паттерн в остатках, нарушено условие независимости или зависимость нелинейная - нельзя.

\vskip0pt plus 1filll

\columnsbegin
\column{0.48\textwidth}
\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz1.png}
\column{0.48\textwidth}

\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz2.png}
\columnsend


\tiny Рис. из кн. Watkins et al. 2008, стр. 177, рис. 3.84-3.85


## Какие наблюдения влияют на ход регрессии больше других?

\columnsbegin
\column{0.48\textwidth}

Влиятельные наблюдения, выбросы, outliers

- большая абсолютная величина остатка
- близость к краям области определения (leverage - рычаг, сила; иногда называют hat)

На графике точки и линии регрессии построенные с их включением:

- 1 - не влияет на ход регрессии, т.к. лежит на прямой
- 2 - умеренно влияет (большой остаток, малая сила влияния)
- 3 - очень сильно влияет (большой остаток, большая сила влияния)


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8

\columnsend

## Как оценить влиятельность наблюдений?

\columnsbegin
\column{0.48\textwidth}

\blockbegin{Расстояние Кука (Cook's d, Cook, 1977)}

- Учитывает одновременно величину остатка и близость к краям области определения (leverage)
- Условное пороговое значение: выброс, если $d \ge 4/(n - p)$, где $n$ - объем выборки, $p$ - число параметров модели.

\blockend

\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8

\columnsend

\pause

- Дж. Фокс советует не обращать внимания на пороговые значения (Fox, 1991)


## Что делать с влиятельными точками и с выбросами?

\columnsbegin
\column{0.48\textwidth}

- Проверить, не ошибка ли это. Если нет, не удалять - обсуждать!
- Проверить, что будет, если их исключить из модели


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8


\columnsend

## Коллинеарность предикторов

\begin{block}{Коллинеарность}
Коллинеарные предикторы коррелируют друг с другом, т.е. не являются взаимно независимыми
\end{block}

Последствия

- Модель неустойчива к изменению данных
- При добавлении или исключении наблюдений может меняться оценка и знак коэффициентов

Что делать с коллинеарностью?

- Удалить из модели избыточные предикторы
- Получить вместо скоррелированных предикторов один новый комбинированный при помощи метода главных компонент

## Проверка на коллинеарность

### Показатель инфляции для дисперсии

(коэффициент распространения дисперсии, Variance inflation factor, VIF)

$$VIF = 1/(1-R^2)$$

Здесь в знаменателе используется $R^2$ регрессии данного предиктора от всех других.


Хорошо, если $VIF < 10$ (по Marquardt, 1970), но лучше $VIF < 3$, а иногда и $VIF < 2$. Если больше --- коллинеарность.

# Проверка условий применимости линейной регрессии

## Как проверить условия применимости?

1. VIF --- коллинеарность предикторов (для множественной регрессии)
2. График расстояния Кука для разных наблюдений --- проверка на наличие выбросов
3. График остатков от предсказанных значений --- величина остатков, влиятельность наблюдений, отсутствие паттернов, гомогенность дисперсий.
4. График квантилей остатков --- распределение остатков

## 1. Проверим, есть ли в этих данных коллинеарность предикторов

```{r message = FALSE}
library(car)
vif(bird_lm) # variance inflation factors
```

\pause
Все в порядке, предикторы независимы

## Для анализа остатков выделим нужные данные в новый датафрейм

```{r}
library(ggplot2) # там есть функция fortify()
bird_diag <- fortify(bird_lm)
# вот, что записано в диагностическом датафрейме
head(bird_diag, 2)
```

\pause

- `.cooksd` - расстояние Кука  
- `.fitted` - предсказанные значения  
- `.resid` - остатки  
- `.stdresid` - стандартизованные остатки

## 2. График расстояния Кука для разных наблюдений

```{r}
ggplot(data = bird_diag, aes(x = 1:nrow(bird_diag), y = .cooksd)) + 
  geom_bar(stat = "identity")
```


## Задача

Постройте график зависимости стандартизованных остатков от предсказанных значений

Используйте данные из `bird_diag`



## 3. График зависимости стандартизованных остатков от предсказанных значений

```{r purl=FALSE}
gg_resid <- ggplot(data = bird_diag, aes(x = .fitted, y = .stdresid)) + 
  geom_point()
gg_resid
```

\pause

Разброс остатков не совсем одинаков, но большая часть стандартизованных остатков в пределах двух стандартных отклонений. Есть отдельные влиятельные наблюдения, которые нужно проверить. Тренда среди остатков нет


## 4. Квантильный график стандартизованных остатков

Используется, чтобы оценить форму распределения. По оси Х --- квантили теоретического распределения, по оси Y --- квантили остатков модели.

Если точки лежат на одной прямой --- все в порядке.

```{r qqplot, warning = FALSE, message=FALSE, fig.width = 6}
library(car)
qqPlot(bird_lm, id = FALSE) # из пакета car
```

## Интерпретируем квантильный график 

Какие выводы можно сделать по квантильному графику?

```{r qqplot, warning = FALSE, message=FALSE, echo=FALSE, purl=FALSE, fig.width = 6}
```
\pause

Отклонений от нормального распределения нет

## Внимание!

Только если все условия выполняются, можно приступить к интерпретации результатов.


## Take-home messages

- Для сравнения влияния разных предикторов можно использовать бета-коэффициенты
- Условия применимости линейной регрессии должны выполняться, чтобы можно было тестировать гипотезы
    1. Независимость
    1. Линейность 
    1. Нормальное распределение
    1. Гомогенность дисперсий
    1. Отсутствие коллинеарности предикторов (для множественной регрессии)

## Дополнительные ресурсы

+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide

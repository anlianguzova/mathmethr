---
title: "Регрессионный анализ, часть 2"
subtitle: "Математические методы в зоологии с использованием R"
author: "Марина Варфоломеева"
classoption: 't,xcolor=table'
language: russian, english
output:
  beamer_presentation:
    colortheme: seagull
    highlight: tango
    fonttheme: structurebold
    latex_engine: xelatex
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - -V fontsize=10pt
    slide_level: 2
    fig_crop: false
    theme: CambridgeUS
    toc: no
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
options(width = 70, scipen = 6)
library(knitr)
opts_chunk$set(fig.show='hold', size='footnotesize', comment='#', warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7)
source('support_mathmethr.R')
```

### Вы сможете

- Подобрать модель множественной линейной регрессии
- Протестировать значимость модели и ее коэффициентов
- Интерпретировать коэффициенты множественной регрессии при разных предикторах
- Проверить условия применимости простой и множественной линейной регрессии при помощи анализа остатков


# Условия применимости линейной регрессии

## Условия применимости линейной регрессии 

Условия применимости линейной регрессии должны выполняться, чтобы тестировать гипотезы

1. Независимость
1. Линейность 
1. Нормальное распределение
1. Гомогенность дисперсий
1. Отсутствие коллинеарности предикторов (для множественной регрессии с этого условия нужно начинать!)

## 1. Независимость

- Значения $y _i$ должны быть независимы друг от друга
- Берегитесь псевдоповторностей и автокорреляций (например, временных)
- Контролируется на этапе планирования
- Проверяем на графике остатков

\vskip0pt plus 1filll
\centering
\includegraphics[width=0.85\linewidth,keepaspectratio]{images/assumption-12.png}

\raggedright
\tiny Из кн. Diez et al., 2010, стр. 332, рис. 7.8

## 2. Линейность связи

- Проверяем на графике рассеяния исходных данных
- Проверяем на графике остатков

\vskip0pt plus 1filll
\centering
\includegraphics[width=0.85\linewidth,keepaspectratio]{images/assumption-12.png}

\raggedright
\tiny Из кн. Diez et al., 2010, стр. 332, рис. 7.8

## Что бывает, если не глядя применять линейную регрессию

\columnsbegin
\column{0.48\textwidth}

\href{http://ru.wikipedia.org/wiki/Квартет_Энскомба}{Квартет Энскомба} - примеры данных, где регрессии одинаковы во всех случаях (Anscombe, 1973)

\[y _i = 3.0 + 0.5 x _i\]

\[r^2 = 0.68\]

\[H _0: \beta _1 = 0, t = 4.24, p = 0.002\]


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/anscombe.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 97, рис. 5.9


\columnsend

## 3. Нормальное распределение остатков

\columnsbegin
\column{0.48\textwidth}
Нужно, т.к. в модели $Y _i = \beta _0 + \beta x _i + \epsilon _i$ зависимая переменная $Y \sim N(0,\sigma^2)$, а значит $\epsilon _i \sim N(0,\sigma^2)$

- Нужно для тестов параметров, а не для подбора методом наименьших квадратов
- Нарушение не страшно --- тесты устойчивы к небольшим отклонениям от нормального распределения
- Проверяем распределение остатков на нормально-вероятностном графике


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/normality-assumption.png}

\raggedright
\tiny Из кн. Watkins et al., 2008, стр. 743, рис. 11.4

\columnsend

## 4. Гомогенность дисперсий

\columnsbegin
\column{0.48\textwidth}
Нужно, т.к. в модели $Y _i = \beta _0 + \beta x _i + \epsilon _i$ зависимая переменная $Y \sim N(0,\sigma^2)$ и дисперсии $\sigma^2 _1 = \sigma^2 _2 = ... = \sigma^2 _i$ для каждого $Y _i$ \par
Но, поскольку $\epsilon _i \sim N(0,\sigma^2)$, можно проверить равенство дисперсий остатков $\epsilon _i$

- Нужно и важно для тестов параметров
- Проверяем на графике остатков по отношению к предсказанным значениям
- Есть формальные тесты, но они очень чувствительны (тест Бройша-Пагана, тест Кокрана)


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/normality-assumption.png}

\raggedright
\tiny Из кн. Watkins et al., 2008, стр. 743, рис. 11.4


\columnsend

## Диагностика регрессии по графикам остатков

\columnsbegin
\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-violations-on-residual-plots.png}

\raggedright
\tiny Из кн. Logan, 2010, стр. 174, рис. 8.5 d


\column{0.48\textwidth}

- (a)все условия выполнены  
- (b)разброс остатков разный (wedge-shaped pattern)  
- (c)разброс остатков одинаковый, но нужны дополнительные предикторы  
- (d)к нелинейной зависимости применили линейную регрессию  

\columnsend

## Задача: Проанализируйте графики остатков

Скажите пожалуйста

- какой регрессии соответствует какой график остатков?
- все ли условия применимости регрессии здесь выполняются?
- назовите случаи, в которых можно и нельзя применить линейную регрессию?

\columnsbegin
\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz1.png}

\column{0.48\textwidth}
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz2.png}

\columnsend

\tiny{Из кн. Watkins et al. 2008, стр. 177, рис. 3.84-3.85}


## Решение

- A-I - нелинейная связь - нельзя; 
- B-II - все в порядке, можно; 
- C-III - все в порядке, можно; 
- D-IV - синусоидальный паттерн в остатках, нарушено условие независимости или зависимость нелинейная - нельзя.

\vskip0pt plus 1filll

\columnsbegin
\column{0.48\textwidth}
\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz1.png}
\column{0.48\textwidth}

\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/assumption-quiz2.png}
\columnsend


\tiny Рис. из кн. Watkins et al. 2008, стр. 177, рис. 3.84-3.85


## Какие наблюдения влияют на ход регрессии больше других?

\columnsbegin
\column{0.48\textwidth}

Влиятельные наблюдения, выбросы, outliers

- большая абсолютная величина остатка
- близость к краям области определения (leverage - рычаг, сила; иногда называют hat)

На графике точки и линии регрессии построенные с их включением:

- 1 - не влияет на ход регрессии, т.к. лежит на прямой
- 2 - умеренно влияет (большой остаток, малая сила влияния)
- 3 - очень сильно влияет (большой остаток, большая сила влияния)


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8

\columnsend

## Как оценить влиятельность наблюдений?

\columnsbegin
\column{0.48\textwidth}

\blockbegin{Расстояние Кука (Cook's d, Cook, 1977)}

- Учитывает одновременно величину остатка и близость к краям области определения (leverage)
- Условное пороговое значение: выброс, если $d \ge 4/(n - p)$, где $n$ - объем выборки, $p$ - число параметров модели. Иногда используют более мягкий порог $d \ge 1$

\blockend

\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8

\columnsend

\pause

- Дж. Фокс советует не обращать внимания на пороговые значения (Fox, 1991)


## Что делать с влиятельными точками и с выбросами?

\columnsbegin
\column{0.48\textwidth}

- Проверить, не ошибка ли это. Если нет, не удалять - обсуждать!
- Проверить, что будет, если их исключить из модели


\column{0.48\textwidth}

\centering
\includegraphics[width=\linewidth,height=\textheight,keepaspectratio]{images/influential-observations.png}

\raggedright
\tiny Из кн. Quinn, Keough, 2002, стр. 96, рис. 5.8


\columnsend

## Коллинеарность предикторов

\begin{block}{Коллинеарность}
Коллинеарные предикторы коррелируют друг с другом, т.е. не являются взаимно независимыми
\end{block}

Последствия

- Модель неустойчива к изменению данных
- При добавлении или исключении наблюдений может меняться оценка и знак коэффициентов

Что делать с коллинеарностью?

- Удалить из модели избыточные предикторы
- Получить вместо скоррелированных предикторов один новый комбинированный при помощи метода главных компонент

## Проверка на коллинеарность

### Показатель инфляции для дисперсии

(коэффициент распространения дисперсии, Variance inflation factor, VIF)

$VIF$ оценивает степень избыточности каждого из предикторов модели:

$$VIF = 1/(1-R'^2)$$

__Здесь в знаменателе используется $R^2$ регрессии данного предиктора от всех других предикторов в модели__.

Хорошо, если $VIF < 10$ (по Marquardt, 1970), но лучше $VIF < 3$, а иногда и $VIF < 2$. Если больше --- есть коллинеарность.

Предикторы с $VIF$ больше порогового значения нужно последовательно удалить из модели (по-одному, проверяя, как изменился $VIF$ после каждого этапа удаления).

# Множественная линейная регрессия

## Пример: реки штата Нью-Йорк

В 70-е годы в штате Нью Йорк обследовали 20 речных бассейнов (Haith, 1976), чтобы оценить качество воды. Как влияют особенности землепользования на среднюю концентрацию азота (мг/л) в воде?  
(Датасет river из пакета bstats, источник Chatterjee & Hadi, 2006)

20 рек в штате Нью Йорк

- `River`	- название реки
- `Agr` - процент сельскохозяйственных земель
- `Forest` - процент земли, занятой лесом
- `Rsdntial` - процент земель, занятых поселениями
- `ComIndl`	- процент земель, занятых коммерцией и промышленностью
- `Nitrogen` - средняя концентрация азота в воде, мг/л

Т.е. мы хотим подобрать модель вида:

$Nitrogen_i = b_0 + b_1 Agr_i + b_2 Forest_i + b_3 Rsdntial_i + b_4 ComIndl_i + e_i$

## Читаем данные из файла одним из способов

### Чтение из xlsx
```{r}
library(readxl)
river <- read_excel(path = "data/river.xlsx", sheet = "river-data")
```

### Чтение из csv

```{r}
river <- read.table("data/river.csv", header = TRUE, sep = "\t")
```

## Все ли правильно открылось?

```{r}
str(river)      # Структура данных
head(river)     # Первые несколько строк файла
```

## Знакомимся с данными

Есть ли пропущенные значения?

```{r}
colSums(is.na(river))
```

Каков объем выборки?

```{r}
nrow(river)
```

## Парные графики для всех числовых переменных

```{r eval=FALSE}
pairs(river[, -1])
```

```{r fig.width = 9, fig.height=4.4, echo=FALSE, purl=FALSE}
pairs(river[, -1], gap = 0.25, oma=rep(1.75, 4))
```

\pause

__Выброс__ — сильно отскакивающее значение. 

Похоже, что в этих данных есть выброс в столбце `Rsdntial`.

## Варианты действий с выбросами

- удалить это наблюдение, т.к. рек с таким большим уровнем застройки территории больше нет в датасете.
- трансформировать `Rsdntial` (извлечь логарифм), чтобы "растянуть" начало шкалы и "сплющить" ее конец.

\pause

\vfill

Мы пока продолжим, чтобы посмотреть как будет выглядеть это значение при анализе остатков.

## Задача

1. Подберите модель множественной линейной регрессии, чтобы описать, как зависит концентрация азота от особенностей землепользования.

$Nitrogen_i = b_0 + b_1 Agr_i + b_2 Forest_i + b_3 Rsdntial_i + b_4 ComIndl_i + e_i$

1. Запишите уравнение этой линейной модели с коэффициентами.

## Решение

\fontsize{10pt}{10pt}
```{r purl=FALSE}
river_lm1 <- lm(Nitrogen ~ Agr + Forest + Rsdntial + ComIndl, data = river)
# summary(river_lm1)
```

Коэффициенты модели:

```{r purl=FALSE}
coef(river_lm1)
```

Уравнение регрессии:

$`r lm_equation(river_lm1, strict=FALSE, digits = 1)`$


\pause

Более формальная запись  
(и та и другая запись требует расшифровки обозначений):  

$`r lm_equation(river_lm1, digits = 1)`$

\pause

__Важно!__ Прежде чем интерпретировать результаты нужно обязательно проверить, выполняются ли условия применимости линейной регрессии.

# Проверка условий применимости линейной регрессии

## Как проверить условия применимости?

1. Вычисляем VIF --- коллинеарность предикторов (для множественной регрессии с этого всегда нужно начинать)
2. График расстояния Кука для разных наблюдений --- проверка на наличие выбросов
3. График остатков от предсказанных значений --- величина остатков, влиятельность наблюдений, отсутствие паттернов, гомогенность дисперсий.
4. График квантилей остатков --- распределение остатков

## 1. Проверка на коллинеарность предикторов

```{r message = FALSE}
library(car)
vif(river_lm1) # variance inflation factors
```

\pause

Самое большое значение vif для предиктора `Forest`. Удалим его из модели и пересчитаем vif.

\pause

```{r}
river_lm2 <- lm(Nitrogen ~ Agr + Rsdntial + ComIndl, data = river)
vif(river_lm2) # variance inflation factors
```

\pause

Самое большое значение vif для предиктора `ComIndl`. Аналогично.

## 1. Проверка на коллинеарность предикторов, продолжение

Удаляем `ComIndl`

```{r}
river_lm3 <- lm(Nitrogen ~ Agr + Rsdntial, data = river)
vif(river_lm3) # variance inflation factors
```

\pause

Все в порядке. Судя по значениям vif после пошагового удаления всех коллинеарных предикторов оставшиеся предикторы независимы. 

Теперь наша модель `river_lm3` выглядит так:

$Nitrogen_i = b_0 + b_1 Agr_i + b_3 Rsdntial_i + e_i$

## Для анализа остатков создадим диангостический датафрейм

```{r}
library(ggplot2) # там есть функция fortify()
river_diag3 <- fortify(river_lm3)
# вот, что записано в диагностическом датафрейме
head(river_diag3, 2)
```

\pause

- `.cooksd` - расстояние Кука  
- `.fitted` - предсказанные значения  
- `.resid` - остатки  
- `.stdresid` - стандартизованные остатки

## 2. Проверка на наличие влиятельных наблюдений

График расстояния Кука для всех наблюдений

```{r}
ggplot(data = river_diag3, aes(x = 1:nrow(river_diag3), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

\pause

Вот оно, то самое отскакивающее значение `Rsdntial` больше 25% застройки. Сейчас оно слишком сильно влияет на ход регрессии. Давайте попробуем его удалить и переподобрать модель.

## Новая модель, на очищенных данных

```{r fig.height=2.25}
# данные без выброса
river_subset <- river[river$Rsdntial < 25, ]
# новая модель
river_lm4 <- lm(Nitrogen ~ Agr + Rsdntial, data = river_subset)
# диагностический датафрейм
river_diag4 <- fortify(river_lm4)
# график расстояния Кука
ggplot(data = river_diag4, aes(x = 1:nrow(river_diag4), y = .cooksd)) + 
  geom_bar(stat = "identity")
```

\pause

Отлично, больше нет чрезмерно влиятельных наблюдений с $d > 1$.

## Задача

Постройте график зависимости стандартизованных остатков от предсказанных значений

Используйте данные из `river_diag4`

```{r resid-plot, purl=FALSE, echo=FALSE}
gg_resid <- ggplot(data = river_diag4, aes(x = .fitted, y = .stdresid)) + 
  geom_point()
gg_resid
```

## 3. График зависимости стандартизованных остатков от предсказанных значений

```{r resid-plot, purl=FALSE, echo=TRUE}
```

\pause

Большая часть стандартизованных остатков в пределах двух стандартных отклонений. В правой части графика мало наблюдений (с большими предсказанными значениями концентрации азота) - с этим ничего не поделаешь... Тренда среди остатков нет.


## 4. Квантильный график стандартизованных остатков

Используется, чтобы оценить форму распределения. По оси Х --- квантили теоретического распределения, по оси Y --- квантили остатков модели.

Если точки лежат на одной прямой --- все в порядке.

```{r qqplot, warning = FALSE, message=FALSE, fig.width = 6, fig.height=5, echo=-c(1, 4)}
op <- par(cex = 0.8, mar = c(4, 4, 1, 1))
library(car)
qqPlot(river_lm4, id = FALSE) # из пакета car
par(op)
```

## Интерпретируем квантильный график 

Какие выводы можно сделать по квантильному графику?

```{r qqplot, warning = FALSE, message=FALSE, echo=FALSE, purl=FALSE, fig.width = 6}
```
\pause

Отклонений от нормального распределения нет

## Внимание!

Только если все условия выполняются, можно приступить к интерпретации результатов тестов значимости коэффициентов регрессии.


## Интерпретация коэффициентов регрессии

```{r}
coef(river_lm4)
```

\pause

### Обычные коэффициенты

- Величина обычных коэффициентов зависит от единиц измерения
- $b_0$ --- Отрезок (Intercept), отсекаемый регрессионной прямой на оси $y$. Значение зависимой переменной $Y$, если предикторы равны нулю.
- Коэффициенты при предикторах показывают, на сколько изменяется $Y$, когда данный предиктор меняется на единицу, при условии, что остальные предикторы не меняют своих значений.

## Если предикторы измерены в разных единицах

Обычные коэффициенты отражают силу влияния предикторов, но не учитывают масштаб их варьирования.

Если стандартизовать переменные ( $x_{std} = \frac{x_i - \bar x}{SD_x}$), то масштабы их изменений выровняются: они будут измеряться в одних и тех же единицах — в стандартных отклонениях.

```{r purl=FALSE, echo=FALSE}
op <- par(mfrow = c(1, 2), mar = c(2, 3, 3, 0.3))
boxplot(river_subset[, c("Agr", "Rsdntial")], main = "Исходно")
boxplot(scale(river_subset[, c("Agr", "Rsdntial")]), main = "После\n стандартизации")
par(op)
```

\pause

Если подобрать по линейную регрессию по стандартизованным значениям предикторов, то можно будет сравнивать силу их влияния с учетом масштаба их варьирования.

## Для сравнения влияния разных предикторов --- стандартизованные коэффициенты

\fontsize{10pt}{10pt}

```{r}
scaled_river_lm4 <- lm(Nitrogen ~ scale(Agr) + scale(Rsdntial), data = river_subset)
coef(scaled_river_lm4)
```

\pause

### Стандартизованные коэффициенты

- Стандартизованные коэффициенты измерены в стандартных отклонениях. Их можно сравнивать друг с другом, поскольку они дают относительную оценку влияния фактора.
- $b_0$ --- Отрезок (Intercept), отсекаемый регрессионной прямой на оси $y$. Значение зависимой переменной $Y$, если предикторы равны нулю. Для стандартизованных величин среднее значение равно нулю, поэтому $b_0$ --- это значение зависимой переменной при средних значениях всех предикторов.
- Коэффициенты при предикторах показывают, на сколько изменяется $Y$, когда предиктор меняется на одно стандартное отклонение, при условии, что остальные предикторы не меняют своих значений. Это относительная оценка влияния фактора.

## Задача

Определите по значениям стандартизованных коэффициентов, какие предикторы сильнее всего влияют на концентрацию азота в воде?

\fontsize{10pt}{10pt}

```{r}
summary(scaled_river_lm4)
```

\pause

Влияние обоих предикторов сопоставимо по силе, но сильнее всего все же влияет процент застройки `Rsdntial`.

## Оценка качества подгонки модели

```{r}
summary(river_lm4)$adj.r.squared
```

### Обычный $R^2$ --- доля объясненной изменчивости

$$R^2 =\frac{SS_{r}}{SS_{t}} = 1 - \frac{SS_{e}}{SS_{t}}$$

__Не используйте обычный $R^2$ для множественной регрессии!__

\pause

### $R^2_{adj}$ --- cкорректированный $R^2$

$$R^2_{adj} = 1 - (1 - R^2) \frac{n - 1}{n - p}$$

где $n - p = df_{e}$, $n - 1 = df_{t}$

$R^2_{adj}$ учитывает число переменных в модели, вводится штраф за каждый новый параметр.

Используйте $R^2 _{adj}$ для сравнения моделей с разным числом параметров.


## Описание результатов

\small

Для описания зависимости концентрации азота в речной воде от особенностей землепользования была подобрана линейная модель: $`r lm_equation(river_lm4, strict=FALSE, digits = 1)`$, где $Agr$ — процент сельскохозяйственных земель, $Rsdntial$ — процент земель, занятых поселениями. Эта модель объяснила `r round(summary(river_lm4)$adj.r.squared * 100, 1)`\% общей изменчивости концентрации азота в речной воде. С увеличением процента застройки и процента сельскохозяйственных земель в бассейнах рек концентрация азота статистически значимо увеличивалась (Табл. \autoref{tab:mreg-coef}). 

```{r echo=FALSE, results='asis', purl=FALSE}
library(xtable)
library(tidyr)
smr <- coef(summary(river_lm4)) %>% data.frame()
# %>% format.data.frame(., digits = 2, nsmall = 1)
smr$Pr...t.. <- format.pval(smr$Pr...t.., eps = 0.01)
rownames(smr)[1] <- "Отрезок"
colnames(smr) <- c("Оценка", "Ст.ошибка", "t", "P")

xtb <- xtable(
  smr,
  caption = "Коэффициенты линейной регрессии, описывающей зависимость средней концентрации азота в воде (мг/л) от характеристик землепользования: Agr — процент сельскохозяйственных земель, Rsdntial — процент земель, занятых поселениями. t --- значение t-критерия, P --- уровень значимости.", digits = c(0, 2, 3, 2, 2),
  label = "tab:mreg-coef")

print.xtable(xtb, comment = F, caption.placement = "top")
```

## Что еще можно сделать?

Можно было бы нарисовать график предсказаний модели. Например, это мог бы быть график зависимости предсказанной концентрации азота от площади застройки, если процент сельскохозяйственных земель зафиксирован на среднем уровне. Однако в этом курсе мы не будем разбирать, как можно построить такой график.


## Take-home messages

- Для сравнения влияния разных предикторов можно использовать бета-коэффициенты
- Условия применимости линейной регрессии должны выполняться, чтобы можно было тестировать гипотезы
    1. Независимость
    1. Линейность 
    1. Нормальное распределение
    1. Гомогенность дисперсий
    1. Отсутствие коллинеарности предикторов (для множественной регрессии)

## Дополнительные ресурсы

+ Кабаков Р.И. R в действии. Анализ и визуализация данных на языке R. М.: ДМК Пресс, 2014
+ Diez, D.M., Barr, C.D. and Çetinkaya-Rundel, M., 2015. OpenIntro Statistics. OpenIntro.
+ Zuur, A., Ieno, E.N. and Smith, G.M., 2007. Analyzing ecological data. Springer Science & Business Media.
+ Quinn G.P., Keough M.J. 2002. Experimental design and data analysis for biologists
+ Logan M. 2010. Biostatistical Design and Analysis Using R. A Practical Guide

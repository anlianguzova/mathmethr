<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Дискриминантный анализ</title>
    <meta charset="utf-8" />
    <meta name="author" content="Марина Варфоломеева" />
    <meta name="author" content="Анастасия Лянгузова" />
    <script src="libs/header-attrs-2.25/header-attrs.js"></script>
    <link href="libs/remark-css-0.0.1/default.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/tamu-fonts.css" rel="stylesheet" />
    <link href="libs/remark-css-0.0.1/ninjutsu.css" rel="stylesheet" />
    <link href="libs/tile-view-0.2.6/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view-0.2.6/tile-view.js"></script>
    <script src="libs/fabric-4.3.1/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble-0.0.1/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble-0.0.1/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <script src="libs/mark.js-8.11.1/mark.min.js"></script>
    <link href="libs/xaringanExtra-search-0.0.1/search.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-search-0.0.1/search.js"></script>
    <script>window.addEventListener('load', function() { window.xeSearch = new RemarkSearch({"position":"bottom-left","caseSensitive":false,"showIcon":false,"autoSearch":true}) })</script>
    <script src="libs/xaringanExtra-progressBar-0.0.1/progress-bar.js"></script>
    <script src="libs/freezeframe-5.0.2/freezeframe.min.js"></script>
    <script src="libs/xaringanExtra-freezeframe-0.0.1/freezeframe-init.js"></script>
    <script id="xaringanExtra-freezeframe-options" type="application/json">{"selector":"img[src$=\"gif\"]","trigger":"click","overlay":false,"responsive":true,"warnings":true}</script>
    <link href="libs/tachyons-4.12.0/tachyons.min.css" rel="stylesheet" />
    <!-- https://github.com/fnaufel/xaringan-smartify-->
    <script
    			  src="https://code.jquery.com/jquery-3.4.1.slim.min.js"
    			  integrity="sha256-pasqAKBDmFT4eHoN2ndd6lN370kFiGUFyTiUHWhU7k8="
    			  crossorigin="anonymous">
    </script>
    <script type="text/javascript" src="https://cdn.jsdelivr.net/gh/fnaufel/xaringan-smartify/smartify.min.js"></script>
    <link rel="stylesheet" href="assets/xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="assets/xaringan.css" type="text/css" />
    <link rel="stylesheet" href="assets/scrollable.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: middle, left, inverse, title-slide

.title[
# Дискриминантный анализ
]
.subtitle[
## Математические модели в зоологии
]
.author[
### Марина Варфоломеева
]
.author[
### Анастасия Лянгузова
]

---




class: middle, center, inverse

## Дискриминантный анализ

---

### Вы сможете

- провести линейный дискриминантный анализ с использованием обучающей выборки и проверить качество классификации на тестовых данных или с использованием кроссвалидации
- проверить условия применимости дискриминантного анализа

---

class: middle, center, inverse

## Дискриминантный анализ

---

## Дискриминантный анализ

&gt; ### Дискриминантный анализ
&gt;
&gt;- метод классификации объектов с учителем (__supervised learning__), т.е. применяется, когда принадлежность объектов к группе заранее известна.


Задачи дискриминантного анализа:

- выяснить, какие признаки лучше всего позволяют классифицировать объекты
- выяснить правило классификации существующих объектов
- классификация новых объектов неизвестной принадлежности по этому правилу

---

## Дискриминантный анализ

Нужно найти такую ось, вдоль которой группы различаются лучше всего, с минимальным перекрыванием.

Как она может проходить?

![](images/discrim0.jpg)

---

## Дискриминантные оси

&gt; ### Дискриминантные оси
&gt;
&gt; - задаются дискриминантными функциями
&gt; - вдоль них минимальное перекрывание групп
&gt; - дискриминантных осей всего на одну меньше чем групп (или столько же, сколько признаков, если признаков меньше, чем групп)

![](images/discrim.jpg)

---

## Дискриминантные функции

&gt; ### Дискриминантные функции
&gt;
&gt; - описывают положение дискриминантных осей


`$$LD _j = d _{1j} X _{1} + d _{2i} X _{2} + ... + d _p X _{p}$$`

- LD --- линейная дискриминантная функция
- d --- коэффициенты линейной дискриминантной функции
- X --- переменные-признаки
- j = 1, ... min(k--1, p) --- число дискриминантных функций
- p --- число признаков
- k --- число классов

--

### Стандартизованные коэффициенты дискриминантной функции

- используются для сравнения переменных, измеренных в разных шкалах используются стандартизованные коэффициенты дискриминантной функции
- большое абсолютное значение  --- большая дискриминирующая способность

---

## Классификация объектов

.pull-left[

&gt; ### Функции классификации
&gt;
&gt;- Описывают __правдоподобие__ того, что объект с заданными свойствами относится к данной группе при данных значениях признаков согласно построенной классификации.




`$$C _{j} = c _{j0} + c _{j1} X _{1} + ... + c _{jp} X _{p}$$`

- С --- функция классификации
- с --- коэффициенты функций классификации
- X --- переменные-признаки
- j = 1, ..., k --- число групп
- p --- число признаков
]

.pull-right[
Для каждого (в том числе, нового) объекта можно вычислить значение всех функций классификации. Какое значение больше --- к такой группе и надо отнести объект.

![](images/discrim-bound.png)

Пример расположения областей принятия решений в линейном дискриминантном анализе с тремя группами

.tiny[
Рис. с сайта http://statweb.stanford.edu/~jtaylo/courses/stats202/lda.html
]
]

---

## Оценка качества классификации

&gt; ### Таблица классификации
&gt;
&gt; число верно или неверно классифицированных объектов (__confusion matrix__)

Было / Стало | Класс А | Класс Б |
-------------|---------|---------|
Класс А      | верно   | неверно (Б вместо А)|
Класс Б      | неверно (A вместо Б) | верно |

---

## Проблема: как оценить качество классификации, чтобы можно было экстраполировать результаты?

Если оценить качество классификации на тех же данных, что были использованы для ее построения --- оценка неадекватная для классификации новых данных из-за "__переобучения__" (overfitting).

### Возможные решения проблемы переобучения

1. Разделить данные на __тренировочное и тестовое подмножества__:
  - тренировочные данные --- для подбора классификации (для обучения)
  - независимые тестовые данные --- для определения качества классификации

2. __Кроссвалидация__ --- разделение на тренировочное и тестовое подмножество повторяют многократно и усредняют оценки качества классификации между повторами.

---

## Требования к данным для дискриминантного анализа

- групп 2 или больше
- в каждой группе 2 и больше признаков
- число объектов должно быть больше, чем число признаков, лучше в несколько раз (в 4, например).
- признаки измерены в интервальной шкале

Кроме того, должны выполняться некоторые условия применимости (см. далее).

---

## Нужные пакеты и функции


```r
# Для дискриминантного анализа
library(MASS)
source("LDA_helper_functions.R")
# Графики
library(ggplot2)
# Чтение данных
library(readxl)
```

---

## Пример: Морфометрия ирисов

Сверхзадача --- научиться классифицировать ирисы по нескольким измерениям цветка


```r
data(iris)
colnames(iris)
```

```
[1] "Sepal.Length" "Sepal.Width"  "Petal.Length" "Petal.Width"  "Species"     
```

```r
colnames(iris) &lt;- c("s_len", "s_wid", "p_len", "p_wid", "Sp")
head(iris)
```

```
  s_len s_wid p_len p_wid     Sp
1   5.1   3.5   1.4   0.2 setosa
2   4.9   3.0   1.4   0.2 setosa
3   4.7   3.2   1.3   0.2 setosa
4   4.6   3.1   1.5   0.2 setosa
5   5.0   3.6   1.4   0.2 setosa
6   5.4   3.9   1.7   0.4 setosa
```

---

## По каким переменным легче всего различить группы?

Чтобы это узнать, построим графики всех пар переменных при помощи функции `pairs()` из базового пакета


```r
pairs(iris[, -5], col = iris$Sp)
```

![](08_da_files/figure-html/pairs-plot-1.png)&lt;!-- --&gt;

Группы не различимы, если использовать любую из переменных отдельно, или даже какую-то пару переменных. Сделаем дискриминантный анализ.

---

class: middle, center, inverse

## I. Дискриминантный анализ на тренировочных и тестовых данных

---

## 1) Разделяем на тренировочные и тестовые данные


```r
# устанавливаем зерно для воспроизводимости результатов
set.seed(764737)
# доля от объема выборки, которая пойдет в тренировочный датасет
smp_size &lt;- floor(0.80 * nrow(iris))
# индексы строк, которые пойдут в тренировочный датасет
in_train &lt;- sample(1:nrow(iris), size = smp_size)
```

---

## 2) На тренировочных данных получаем стандартизованные коэффициенты главных компонент 


```r
pca_tr_scaled &lt;- rda(iris[in_train, -5], scale = TRUE)
summary(pca_tr_scaled)
```

```

Call:
rda(X = iris[in_train, -5], scale = TRUE) 

Partitioning of correlations:
              Inertia Proportion
Total               4          1
Unconstrained       4          1

Eigenvalues, and their contribution to the correlations 

Importance of components:
                        PC1   PC2    PC3     PC4
Eigenvalue            2.910 0.927 0.1416 0.02135
Proportion Explained  0.728 0.232 0.0354 0.00534
Cumulative Proportion 0.728 0.959 0.9947 1.00000

Scaling 2 for species and site scores
* Species are scaled proportional to eigenvalues
* Sites are unscaled: weighted dispersion equal on all dimensions
* General scaling constant of scores:  4.671 


Species scores

        PC1     PC2    PC3     PC4
s_len  2.08 -0.8449 -0.635 -0.0860
s_wid -1.04 -2.0774  0.216  0.0447
p_len  2.32 -0.0274  0.129  0.2731
p_wid  2.26 -0.1541  0.553 -0.1802


Site scores (weighted sums of species scores)

         PC1       PC2      PC3      PC4
38  -0.63743 -0.277524  0.03884  0.39516
124  0.35095  0.179245 -0.02509 -0.44011
102  0.30350  0.280991  0.61400  0.09631
101  0.48855 -0.409630  1.13102  0.13376
107  0.09389  0.668282  1.18056  0.36349
18  -0.55114 -0.235461 -0.04216 -0.29395
117  0.39079 -0.143652  0.01312  0.45205
42  -0.48161  1.006285 -0.17989 -0.90731
47  -0.59772 -0.510432  0.07072  0.44676
34  -0.60734 -0.966195 -0.11566  0.14423
131  0.64078 -0.155635 -0.90139  0.04502
54   0.10515  0.744046 -0.00599 -0.22907
50  -0.55716 -0.024476 -0.15926 -0.16626
83   0.06830  0.313341 -0.17363 -0.09375
58  -0.12646  0.793439  0.32989  0.08667
104  0.38076 -0.008577  0.16935  0.69006
81   0.03524  0.660032 -0.15404 -0.00139
129  0.46938  0.050696  0.28889 -0.11214
80  -0.00560  0.436862 -0.36254 -0.21886
3   -0.60090  0.132521  0.08220 -0.10754
1   -0.57017 -0.231381 -0.13793 -0.08681
79   0.18008  0.071009  0.08886  0.09025
98   0.15841  0.037218 -0.33173  0.04310
59   0.25069 -0.048894 -0.72146  0.07692
43  -0.65098  0.196396  0.39646  0.17459
29  -0.53862 -0.159865 -0.30573 -0.26760
66   0.23971 -0.259249 -0.62388 -0.32410
5   -0.60171 -0.302896  0.02986  0.09398
61  -0.03336  1.142743 -0.00750 -0.08102
143  0.30350  0.280991  0.61400  0.09631
100  0.07278  0.237114  0.10947  0.15324
134  0.29602  0.098048 -0.22985  0.54138
64   0.19475  0.053167 -0.09214  0.47668
145  0.52982 -0.493850  0.68271 -0.65242
63   0.14639  0.742637 -0.88014 -0.16464
96   0.03256  0.055265  0.14954  0.67054
90   0.07544  0.558433  0.12009 -0.05558
149  0.36794 -0.471091  1.04867 -0.09118
19  -0.47002 -0.642577 -0.45226 -0.18797
25  -0.56289 -0.076277  0.16212  0.79192
53   0.33463 -0.307490 -0.68879 -0.03599
99  -0.11440  0.654915  0.24990 -0.63181
118  0.65045 -1.161713 -0.23931  0.82895
55   0.28690  0.057043 -0.48819 -0.33005
121  0.54000 -0.435465  0.21860 -0.51298
45  -0.53416 -0.519540  0.29158  0.44250
12  -0.58840 -0.075330  0.13282  0.38191
56   0.10679  0.235852  0.14853  0.69991
15  -0.54456 -0.843824 -0.57554 -0.58473
105  0.49240 -0.160920  0.42553  0.03351
97   0.06644  0.143991  0.18228  0.37665
46  -0.52697  0.292447 -0.04310 -0.44555
60   0.00619  0.432928  0.64645  0.05624
11  -0.54128 -0.481184 -0.31635 -0.05879
35  -0.53565  0.182114 -0.17082 -0.10904
95   0.07944  0.350896  0.16095  0.29720
49  -0.55798 -0.459893 -0.21159  0.03526
125  0.45371 -0.477528  0.29960  0.17612
32  -0.45868 -0.210925 -0.31392 -0.73330
41  -0.57634 -0.213854  0.05283 -0.33657
120  0.32654  0.719079 -0.30360  0.16637
140  0.49130 -0.333550 -0.06529 -0.59546
115  0.38378  0.167782  1.15592 -0.85262
94  -0.09492  0.864954  0.16209 -0.09412
109  0.52394  0.276853 -0.48230  0.24023
133  0.48841  0.046616  0.38467 -0.31928
16  -0.55710 -1.202868  0.00223 -0.14797
21  -0.47973 -0.203395 -0.48594 -0.04569
144  0.54031 -0.414804  0.34289 -0.14560
9   -0.59793  0.474501  0.21710  0.05102
75   0.19180 -0.005365 -0.54124 -0.14499
146  0.49381 -0.205690  0.25320 -1.18173
73   0.32357  0.377100 -0.43850  0.00780
84   0.27981  0.250649  0.11715  0.52963
92   0.17140 -0.039324 -0.03886  0.42676
70   0.04558  0.545618 -0.18598  0.12798
106  0.72503 -0.393570 -0.74443  0.29949
135  0.31581  0.328748 -0.19337  1.44645
85   0.06506  0.105951  0.78044  0.74127
20  -0.58719 -0.514197  0.15674  0.10296
69   0.31742  0.678074 -0.56194 -0.70507
72   0.13106  0.152263 -0.31932 -0.35961
88   0.27271  0.572452 -0.80497 -0.43476
111  0.36514 -0.336164  0.29169 -0.33541
112  0.42067  0.152611  0.00500 -0.19462
8   -0.56351 -0.117598 -0.08645  0.05715
52   0.20230 -0.292577 -0.14103 -0.02569
62   0.12303  0.000441  0.22736 -0.13896
6   -0.51593 -0.675590  0.02082 -0.02623
82   0.00771  0.664428 -0.25958  0.06908
14  -0.67400  0.408012  0.25983  0.02895
91   0.07558  0.468444  0.12642  0.78498
51   0.30045 -0.416877 -0.84581 -0.10949
57   0.20679 -0.368804  0.14207  0.22130
10  -0.55468  0.186195 -0.26660  0.09810
110  0.60275 -0.879990  0.38712 -0.31573
23  -0.70250 -0.216468  0.40982 -0.07651
48  -0.60909  0.153497  0.19672  0.12317
103  0.58204 -0.284904 -0.28902 -0.18696
130  0.49511 -0.285478 -0.88242  0.61801
40  -0.54682 -0.138889 -0.19121 -0.03689
89   0.02639  0.072791  0.34031  0.42078
13  -0.56503  0.300608 -0.23465 -0.03127
142  0.50384 -0.340765  0.09696 -1.41974
139  0.24781 -0.034986  0.46854 -0.03441
31  -0.54385  0.203090 -0.05630  0.12167
116  0.42253 -0.327745  0.70331 -0.58943
7   -0.61976 -0.036197  0.41858  0.08953
128  0.27301 -0.056593  0.37355  0.00822
148  0.40334 -0.150866  0.17538 -0.37223
86   0.12485 -0.397105  0.49985  0.31685
36  -0.55931  0.068962 -0.24183 -0.52634
77   0.33496 -0.003382 -0.87870 -0.13172
127  0.31090  0.108045  0.13294 -0.39599
65  -0.00127  0.167176  0.22844 -0.34931
138  0.35925 -0.215167  0.18092  0.63284
4   -0.58574  0.245989  0.14344  0.17309
27  -0.51696 -0.126074  0.11487 -0.22045
74   0.17155  0.154135 -0.34673  0.80420
108  0.60721 -0.223701 -0.80984  0.70629
```

---

## 3) Извлекаем из тренировочных данных site scores по всем главным компонентам 


```r
sites_tr_pca &lt;- scores(pca_tr_scaled, display = 'sites', choices = c(1:4),
                       scaling = 'sites', correlation = TRUE)
head(sites_tr_pca, 2)
```

```
        PC1      PC2       PC3      PC4
38  -0.5437 -0.13357  0.007309  0.02887
124  0.2994  0.08627 -0.004721 -0.03215
```

---

## 4) На тренировочных данных получаем стандартизованные коэффициенты дискриминантных функций


```r
lda_tr_pca &lt;- lda(sites_tr_pca, iris$Sp[in_train])
# коэффициенты дискриминантных функций
lda_tr_scaled$scaling
```

```
          LD1     LD2
s_len  0.8464  0.1042
s_wid  0.6601 -0.9780
p_len -4.0679  1.2173
p_wid -2.1417 -1.8351
```

По ним можно оценить вклады разных признаков в изменчивость вдоль дискриминантных осей.

---

## 5) На тренировочных данных получаем функции классификации


```r
lda_tr &lt;- lda.class(sites_tr_pca, iris$Sp[in_train])
# Коэф. функций классификации
lda_tr$class.funs
```

```
          setosa virginica versicolor
constant  -31.44    -2.111     -17.96
PC1      -124.74    30.098      93.96
PC2       -28.17     9.977      17.62
PC3       -77.56    13.958      63.81
PC4       -60.47    20.040      39.38
```

По ним можно классифицировать объекты.

---

## 6) Оцениваем качество классификации на тренировочных данных


```r
lda_tr_pred &lt;- predict(lda_tr)
table(iris$Sp[in_train], lda_tr_pred$class)
```

```
            
             setosa versicolor virginica
  setosa         39          0         0
  versicolor      0         42         1
  virginica       0          1        37
```

- Какова доля неправильно классифицированных случаев?

---

## 7) График классификации тренировочных данных 


```r
class_df &lt;- data.frame(lda_tr_pred$x,
                       gr = lda_tr_pred$class,
                       real_gr = iris$Sp[in_train])
ggplot(data = class_df, aes(x = LD1, y = LD2, colour = gr)) +
  geom_text(size = 3, aes(label = real_gr)) +
  theme(legend.position = "none")
```

![](08_da_files/figure-html/unnamed-chunk-9-1.png)&lt;!-- --&gt;

---

## 8) Оценка качества классификации на тестовых данных

Самое важное, если мы хотим использовать классификацию для прогноза


```r
# получаем PCA на тестовых данных
pca_pred_scaled &lt;- rda(iris[-in_train, -5], scale = TRUE)

# извлекаем site scores
sites_pred_pca &lt;- as.data.frame(scores(pca_pred_scaled, display = 'sites', choices = c(1:4),
                                       scaling = 'sites', correlation = TRUE))

# делаем предсказания
lda_test_pred &lt;- predict(lda_tr, sites_pred_pca)
table(iris$Sp[-in_train], lda_test_pred$class)
```

```
            
             setosa versicolor virginica
  setosa         11          0         0
  versicolor      0          5         2
  virginica       0          0        12
```

- Какова доля неправильно классифицированных случаев?

---

## 9) График классификации тестовых данных

Можно отметить неправильно классифицированные случаи своим цветом


```r
class_df &lt;- data.frame(lda_test_pred$x,
                       new = lda_test_pred$class,
                       real = iris$Sp[-in_train])
class_df$Group &lt;- factor(paste(class_df$real, class_df$new, sep = " as "))

ggplot(data = class_df, aes(x = LD1, y = LD2)) +
  geom_point(aes(colour = Group))
```

![](08_da_files/figure-html/unnamed-chunk-11-1.png)&lt;!-- --&gt;

---

class: middle, center, inverse

## II. Дискриминантный анализ с кроссвалидацией

---

## Кроссвалидация


```r
# главные компоненты
pca_cv_scaled &lt;- rda(iris[, -5], scale = TRUE)

# site scores
sites_cv_pca &lt;- scores(pca_cv_scaled, display = 'sites', choices = c(1:4),
                       scaling = 'sites', correlation = TRUE)

# дискриминантый анализ и кросс-валидация
lda_cv &lt;- lda(sites_cv_pca, iris$Sp, CV = TRUE)
names(lda_cv)
```

```
[1] "class"     "posterior" "call"     
```

```r
table(iris$Sp, lda_cv$class)
```

```
            
             setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         48         2
  virginica       0          1        49
```

`lda_cv$class` --- показывает, как классифицированы строки, если классификация обучена по остальным данным

---

## График классификации


```r
ggplot(data = iris, aes(x = p_len,
                        y = s_wid,
                        colour = Sp,
                        shape = lda_cv$class)) +
  geom_point(size = 3) +
  scale_shape_discrete("Classified as")
```

![](08_da_files/figure-html/unnamed-chunk-13-1.png)&lt;!-- --&gt;

---

class: middle, center, inverse

## Дискриминантый анализ главных компонент: пакет adegenet

---

## Определение количества осей главных компонент для конкретных данных

### Кросс-валидация 


```r
library(adegenet) # подгружаем библиотеку
iris_xval &lt;- xvalDapc(iris[, -5], iris$Sp, n.pca.max = 300, training.set = 0.8,
                      result = "overall", center = TRUE, scale = TRUE,
                      n.pca = NULL, n.rep = 100, xval.plot = TRUE)
```

![](08_da_files/figure-html/unnamed-chunk-14-1.png)&lt;!-- --&gt;

---

## Извлекаем подобранное количество осей главных компонент


```r
iris_xval$`Number of PCs Achieving Highest Mean Success`
```

```
[1] "3"
```

```r
iris_xval$`Number of PCs Achieving Lowest MSE`
```

```
[1] "3"
```

```r
iris_xval$`Root Mean Squared Error by Number of PCs of PCA` # здесь чем меньше значение, тем лучше 
```

```
      1       2       3 
0.08420 0.08718 0.03771 
```

---

## DPCA непосредственно


```r
iris_dapc &lt;- dapc(iris[, -5], n.pca = 3, n.da = 2, iris$Sp) # здесь число осей, соответственно результатам кросс-валидации
iris_dapc
```

```
	#################################################
	# Discriminant Analysis of Principal Components #
	#################################################
class: dapc
$call: dapc.data.frame(x = iris[, -5], grp = iris$Sp, n.pca = 3, n.da = 2)

$n.pca: 3 first PCs of PCA used
$n.da: 2 discriminant functions saved
$var (proportion of conserved variance): 0.995

$eig (eigenvalues): 2276 19.17  vector    length content                   
1 $eig      2      eigenvalues               
2 $grp      150    prior group assignment    
3 $prior    3      prior group probabilities 
4 $assign   150    posterior group assignment
5 $pca.cent 4      centring vector of PCA    
6 $pca.norm 4      scaling vector of PCA     
7 $pca.eig  4      eigenvalues of PCA        

  data.frame    nrow ncol content                                          
1 $tab          150  3    retained PCs of PCA                              
2 $means        3    3    group means                                      
3 $loadings     3    2    loadings of variables                            
4 $ind.coord    150  2    coordinates of individuals (principal components)
5 $grp.coord    3    2    coordinates of groups                            
6 $posterior    150  3    posterior membership probabilities               
7 $pca.loadings 4    3    PCA loadings of original variables               
8 $var.contr    4    2    contribution of original variables               
```

---

## Визуализация полученных результатов

### Классификация


```r
my_col &lt;- c("#50A8FF", "#50FF7F", "#FF50D7") #выбираем красивые цвета
scatter(iris_dapc, col = my_col, xax = 1, yax = 2, cex = 2, scree.da=FALSE, legend = FALSE, grp = iris$Sp)
```

![](08_da_files/figure-html/unnamed-chunk-17-1.png)&lt;!-- --&gt;

---

## Визуализация полученных результатов

### Графики предсказаний

.pull-left[

```r
assignplot(iris_dapc)
```

![](08_da_files/figure-html/unnamed-chunk-18-1.png)&lt;!-- --&gt;
]

.pull-right[

```r
compoplot(iris_dapc, lab = "", 
          ncol = 1, col = my_col)
```

![](08_da_files/figure-html/unnamed-chunk-19-1.png)&lt;!-- --&gt;
]

---

class: middle, center, inverse

## Условия применимости дискриминантного анализа

---

## Условия применимости дискриминантного анализа

- __признаки независимы друг от друга__ (чтобы не было избыточности, чтобы можно было инвертировать матрицы). Именно поэтому дискр. анализ часто применяется после анализа главных компонент.
- внутригрупповые ковариации приблизительно равны
- распределение признаков --- многомерное нормальное

--

Если условия применимости нарушены:

- В некоторых случаях, дискриминантный анализ дает хорошо работающие классификации.

- Возможно, другие методы, с менее жесткими требованиями, дадут классификации лучшего качества (например, квадратичный дискриминантный анализ --- quadratic discriminant analysis, дискриминантный анализ с использованием ядер --- kernel discriminant analysis)
]

---

## Проверка условий применимости

В данном случае, как и во многих других, они не выполняются, но мы уже убедились, что классификация работает...

---

## Mногомерная нормальность


```r
x &lt;- as.matrix(iris[, -5])
d &lt;- mahalanobis(x, colMeans(x), cov(x))
qqplot(qchisq(ppoints(nrow(x)), df = ncol(x)), d,
  main="QQ график для оценки многомерной нормальности",
  ylab="Расстояние Махаланобиса")
abline(a = 0, b = 1)
```

![](08_da_files/figure-html/unnamed-chunk-20-1.png)&lt;!-- --&gt;

---

## Гомогенность ковариационных матриц

.small[


```r
BoxMTest(as.matrix(iris[, -5]), iris$Sp)
```

```
------------------------------------------------
 MBox Chi-sqr. df P
------------------------------------------------
  146.6632   140.9430          20       0.0000
------------------------------------------------
*Covariance matrices are significantly different.
```

```
$MBox
setosa 
 146.7 

$ChiSq
*setosa 
 140.9 

$df
[1] 20

$pValue
   setosa 
3.352e-20 
```
]

--

Нет гомогенности :(

---

class: middle, center, inverse

## Квадратичный дискриминантный анализ 

---

## Квадратичный дискриминантый анализ

Идея --- та же, что в основе линейного дискриминантного анализа. Отличие в том, что мы не предполагаем, что средние матриц ковариаций должны быть идентичными у разных групп сравнения. При этом изменяется т.н. `decision boundary` --- граница, по которой определяется принадлежность объекта к той или иной группе. 

![](08_da_files/figure-html/lda_va_qda_code-1.png)&lt;!-- --&gt;


---

## Квадратичный дискриминантный анализ в R


```r
# Тренировочные данные
qda_tr &lt;- qda(sites_tr_pca, iris$Sp[in_train])
qda_tr_pred &lt;- predict(qda_tr)
table(qda_tr_pred$class, iris$Sp[in_train])
```

```
            
             setosa versicolor virginica
  setosa         39          0         0
  versicolor      0         42         1
  virginica       0          1        37
```

```r
# Тестовые данные
qda_test_pred &lt;- predict(qda_tr, sites_pred_pca)
table(qda_test_pred$class, iris$Sp[-in_train])
```

```
            
             setosa versicolor virginica
  setosa         11          0         0
  versicolor      0          5         0
  virginica       0          2        12
```

---

## Кроссвалидация QDA


```r
qda_cv &lt;- qda(sites_cv_pca, iris$Sp, CV = TRUE)
table(iris$Sp, lda_cv$class)
```

```
            
             setosa versicolor virginica
  setosa         50          0         0
  versicolor      0         48         2
  virginica       0          1        49
```

---

## График предсказаний QDA


```r
ggplot(data = iris, aes(x = p_len,
                        y = s_wid,
                        colour = Sp,
                        shape = lda_cv$class)) +
  geom_point(size = 3) +
  scale_shape_discrete("Classified as")
```

![](08_da_files/figure-html/unnamed-chunk-24-1.png)&lt;!-- --&gt;



---

## Take-home messages

- Дискриминантный анализ --- метод классификации объектов по правилам, выработанным на выборке объектов с заранее известной принадлежностью

- Качество классификации можно оценить по числу неверно классифицированных объектов. Чтобы не было "переобучения" можно:
  - Подобрать классификацию на тренировочных данных и проверить на тестовых
  - Использовать кроссвалидацию --- классификацию объектов по правилам полученным по остальным данным (без учета этих объектов)

- Для дискриминантного анализа нужно отбирать признаки, независимые друг от друга или создавать синтетические признаки при помощи анализа главных компонент.

- Если внутригрупповые ковариации признаков различаются, лучше применять квадратичный дискриминантный анализ.

---

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 435--441 

    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script src="assets/macros.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "vs",
"highlightLines": true,
"countIncrementalSlides": false
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
// add `data-at-shortcutkeys` attribute to <body> to resolve conflicts with JAWS
// screen reader (see PR #262)
(function(d) {
  let res = {};
  d.querySelectorAll('.remark-help-content table tr').forEach(tr => {
    const t = tr.querySelector('td:nth-child(2)').innerText;
    tr.querySelectorAll('td:first-child .key').forEach(key => {
      const k = key.innerText;
      if (/^[a-z]$/.test(k)) res[k] = t;  // must be a single letter (key)
    });
  });
  d.body.setAttribute('data-at-shortcutkeys', JSON.stringify(res));
})(document);
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>
<!-- https://github.com/fnaufel/xaringan-smartify-->
<script type="text/javascript">
  smartify();
</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>

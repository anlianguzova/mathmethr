---
title: "Анализ мощности"
subtitle: "Математические методы в зоологии с использованием R"
author: "Марина Варфоломеева"
classoption: 't,xcolor=table'
language: russian, english
output:
  beamer_presentation:
    colortheme: seagull
    highlight: tango
    fonttheme: structurebold
    latex_engine: xelatex
    includes:
      in_header: ./includes/header.tex
    pandoc_args:
    - -V fontsize=10pt
    slide_level: 2
    fig_crop: false
    theme: CambridgeUS
    toc: no
---

```{r setup, include = FALSE, cache = FALSE, purl = FALSE}
# output options
options(width = 70, scipen = 6)
library(knitr)
opts_chunk$set(fig.show='hold', size='footnotesize', comment='#', warning=FALSE, message=FALSE, dev='cairo_pdf', fig.height=2.5, fig.width=7.7)
source('support_mathmethr.R')
```

```{r libs, echo=FALSE}
library(ggplot2)
theme_set(theme_bw())
library(grid)
library(gridExtra) # to rescale legend
```

## Экономим силы с помощью анализа мощности

  - Тестирование гипотез (двухвыборочный t-критерий)
  - Статистические ошибки при проверке гипотез
  - Мощность статистического теста
  - *A priori* анализ мощности, оценка величины эффекта
  - Как влиять на мощность тестов

### Вы сможете

  - сравнивать средние значения при помощи t-критерия, интерпретировать и описывать результаты
  - дать определение ошибок I и II рода, и графически изобразить их отношение к мощности теста
  - оценивать величину эффекта и необходимый объем выборки по данным пилотного исследования
  - загружать данные из .xlsx в R
  - строить графики средних значений со стандартными отклонениями с помощью `ggplot2`

  
# Тестирование гипотез

## Тест Стьюдента (t-критерий)

Гипотезы: $H_0: \mu_1 - \mu_2 = 0$, $H_A: \mu_1 - \mu_2 \ne 0$

Двухвыборочный тест Стьюдента (Student, 1908) используется для проверки значимости различий между средними значениями двух величин.

$$t= \frac{\bar{x}_1 - \bar{x}_2}{SE_{\bar{x}_1 - \bar{x}_2}}$$

Условия применимости:

- Наблюдения случайны и независимы друг от друга
- Выборки случайны и независимы друг от друга
- Величины нормально распределены или большая выборка (> 30 наблюдений в группе)
- __Дисперсии в группах одинаковы__
$$SE = \sqrt{\frac{s_1^2(n_1-1) +s_2^2(n_2-1)}{n_1+n_2-2}\Big(\frac{1}{n_1} + \frac{1}{n_2}\Big)}$$

$$df = (n_1 - 1) + (n_2 - 1) = n_1 + n_2 - 2$$

## t-тест Уэлча --- это модификация теста Стьюдента __для случая разных дисперсий__

$$t= \frac{\bar{x}_1 - \bar{x}_2}{SE_{\bar{x}_1 - \bar{x}_2}}$$

Условия применимости:

- Наблюдения случайны и независимы друг от друга
- Выборки случайны и независимы друг от друга
- Величины нормально распределены или большая выборка (> 30 наблюдений в группе)


$$SE = \sqrt{{s_1^2}/ {n_1} + {s_2^2}/{n_2}}$$

Приблизительное число степеней свободы рассчитывается по уравнению Уэлча-Саттеруэйта 

$$df_{ Welch-Satterthwaite} \approx \cfrac {({s^2_{1}}/{n_{1}} + {s^2_{x_2}}/{n_{2}})^2}
{\frac{1}{n_{1} - 1}\bigg(\frac {s_{1}^2} {n_{1}}\bigg)^2 + \frac{1}{n_{2} - 1}\bigg(\frac {s_{2}^2} {n_{2}}\bigg)^2}$$

## t-распределение --- распределение разницы средних для выборок из одной совокупности

t-статистика подчиняется t-распределению.

Иными словами, если много раз взять выборки __из одной__ совокупности (т.е. при условии, что $H_0$ верна) и посчитать между ними разницу, то она будет подчиняться t-распределению. 

Форма t-распределения зависит только от одного параметра --- числа степеней свободы $df$

```{r gg-t, echo=FALSE, purl=FALSE}
t_df <- data.frame(t = seq(-6, 6, length.out = 1000))

gg_t <- ggplot(data = t_df, aes(x = t)) +
  stat_function(fun = dt, args=list(df=18), size = 1, geom='line', colour='darkred') + 
    labs(x = 't', 
       y = 'Плотность\nвероятности', 
       title = 't-распределение, df = 18')

gg_t
```

## В хвостах этого распределения находятся редкие значения

```{r gg-tcrit, echo=FALSE, purl=FALSE}
alpha <- 0.05
df <- 18
sides <- 2
p_cut <- abs(qt(p = alpha/sides, df = df))
gg_t + 
  # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom = 'area', fill = 'red', alpha = 0.7) + 
  stat_function(fun = dt, args=list(df=df), 
                geom = 'line', colour = 'darkred') +
  labs(title = 't-распределение, df = 18, alpha = 0.05') + 
  # редкие
  geom_vline(xintercept = p_cut, size = 1, linetype = 'dotted') +
  geom_vline(xintercept = -p_cut, size = 1, linetype = 'dotted') +
    annotate(geom = 'text', x = -p_cut, y = 0.4, hjust = 1.1, 
           label = '-t и t при alpha 0.05') 
```

Обычно используется уровень значимости $\alpha$ 0.05 или 0.01. 

__Уровень значимости $\alpha$ --- это вероятность ошибочно отвергнуть справедливую нулевую гипотезу__. Т.е. это вероятность найти различия там, где их нет (__вероятность ошибки I рода__).

Для t-теста  $\alpha$ --- это вероятность ошибочно сделать вывод о том, что средние выборок различаются __при условии, что эти выборки получены из одной генеральной совокупности__.

## Тестирование гипотезы о равенстве двух средних при помощи t-теста

```{r gg-tcrit-h, echo=FALSE, purl=FALSE}
gg_t + 
    # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom='area', fill='red', alpha = 0.7) + 
  stat_function(fun=dt, args=list(df=df), 
                geom='line', colour='darkred') + 
    labs(title = 't-распределение, df = 18, alpha = 0.05') + 
# Зоны решений
  geom_segment(x=-1.5, xend = -1.5, y=0, yend = 0.2) +
  annotate(geom = 'text', x = -3, y = 0.25,
           label = '|t| < |t_crit| \n Не можем отвергнуть H0') +
  geom_segment(x=2.7, xend = 2.7, y=0, yend = 0.2) +
  annotate(geom = 'text', x = 2.7, y = 0.25, 
           label = '|t| >= |t_crit| \n Отвергаем H0')
```

1. Для конкретных данных считаем значение t-критерия
2. Сравниваем его с теоретическим распределением t (распределением при условии, что $H_0$ верна)
3. Принимаем решение, отвергнуть ли $H_0$

## Пример: Снотворное

В датасете `sleep` содержатся данные об увеличении продолжительности сна по сравнению с контролем после применения двух снотворных препаратов (Cushny, Peebles, 1905, Student, 1908)

```{r}
data(sleep)
# View(sleep)
```


## Двухвыборочный t-критерий в R рассчитывает функция `t.test()`

О параметрах функции t.test() можно прочесть в справке `?t.test`

Формат вызова функции, если в данных две группы

```
t.test(formula = зависимая_переменная ~ группирующая_переменная, data = данные, ...)
```

Если групп больше двух --- другой формат

```
t.test(x = одна_группа, y = другая_группа, ...)
```

## Различается ли изменение продолжительности сна при применении этих двух снотворных?

\fontsize{10pt}{10pt}
```{r}
tt <- t.test(formula = extra ~ group, data = sleep)
tt
```

\pause

Результаты можно описать, например, так:

- Различия изменения продолжительности сна при применении двух препаратов были недостоверны ($t_{`r round(tt$parameter, 2)`} = `r round(tt$statistic, 2)`$, $p = `r format.pval(tt$p.value, eps = 0.01)`$)


## Что спрятано в результатах?

Как называются отдельные элементы результатов можно узнать посмотрев их структуру при помощи функции `str()`

```{r}
str(tt)
```

## Можно получить элементы результатов в виде отдельных цифр

```{r purl=FALSE}
tt$parameter # степени свободы
tt$p.value # уровень значимости
tt$statistic # значение t-критерия
```

# Статистические ошибки при проверке гипотез

## Типы ошибок при проверке гипотез

| 	|$$H0 == TRUE$$ |	$$H0 == FALSE$$ |
|-----|-----|-----|
| Отклонить $H_0$ 	| Ошибка I рода | 	Верно |
| Сохранить $H_0$ 	| Верно | Ошибка II рода |

## Ошибка I рода

\small

| 	|$$H0 == TRUE$$ |	$$H0 == FALSE$$ |
|-----|-----|-----|
| Отклонить $H_0$ 	| Ошибка I рода | 	Верно |
| Сохранить $H_0$ 	| Верно | Ошибка II рода |

\normalsize


```{r power_alpha, echo = FALSE, fig.height=3, fig.width=10.1, purl = FALSE}
gg_alpha <- gg_t + 
  # alpha
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides), 
                geom = 'area', fill = 'red', alpha = 0.7) + 
  # H_0 curve
  stat_function(fun = dt, args=list(df = df), 
                geom = 'line', colour = 'darkred') + 
  # labs
  labs(title = 't-распределение, df = 18, alpha = 0.05') +
  # limits
  geom_vline(xintercept = p_cut, size = 1, linetype = 'dotted') +
  geom_vline(xintercept = -p_cut, size = 1, linetype = 'dotted') +
    annotate(geom = 'text', x = -p_cut, y = 0.4, hjust = 1.1,
           label = '-t и t при alpha 0.05')
gg_alpha
```

__Ошибка I рода --- вероятность отвергнуть $H_0$, когда верна $H_0$__

## Мы этого не знаем, но может быть верна $H_A$...

\small

| 	|$$H0 == TRUE$$ |	$$H0 == FALSE$$ |
|-----|-----|-----|
| Отклонить $H_0$ 	| Ошибка I рода | 	Верно |
| Сохранить $H_0$ 	| Верно | Ошибка II рода |

\normalsize


```{r power_alternative, echo = FALSE, fig.height=3, fig.width=10.1, purl = FALSE}
nc <- 0.5
gg_alpha +
    stat_function(fun = dt, 
                args = list(df = df, ncp = nc), 
                geom = 'line', colour = 'steelblue', size = 1)
```

Можно построить еще одно распределение статистики --- распределение, при условии того, что верна $H_A$

## Ошибка II рода

\small

| 	|$$H0 == TRUE$$ |	$$H0 == FALSE$$ |
|-----|-----|-----|
| Отклонить $H_0$ 	| Ошибка I рода | 	Верно |
| Сохранить $H_0$ 	| Верно | Ошибка II рода |

\normalsize


```{r power_beta, echo = FALSE, fig.height=3, fig.width=10.1, purl = FALSE}
gg_beta <- gg_alpha + 
    # beta
  stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides,
                            ncp = nc, what = 'beta'), 
                geom = 'area', fill='steelblue', alpha = 0.7) +
# H_A curve
  stat_function(fun = dt, 
                args = list(df = df, ncp = nc), 
                geom = 'line', colour = 'steelblue', size = 1)
gg_beta
```

__Ошибка II рода --- вероятность принять $H_0$, когда верна__ $H_A$

## Мощность теста --- способность выявлять различия

\small

| 	|$$H0 == TRUE$$ |	$$H0 == FALSE$$ |
|-----|-----|-----|
| Отклонить $H_0$ 	| Ошибка I рода | 	Верно |
| Сохранить $H_0$ 	| Верно | Ошибка II рода |

\normalsize

```{r power-power, echo = FALSE, fig.height=3, fig.width=10.1, purl = FALSE}
gg_power <- gg_beta +
# power
    stat_function(fun = dt_limit, 
                args = list(alph = alpha, df = df, sides = sides,
                            ncp = nc, what = 'power'), 
                geom = 'area', fill='seagreen2', alpha = 0.7) +
# H_A curve
  stat_function(fun = dt, 
                args = list(df = df, ncp = nc), 
                geom = 'line', colour = 'steelblue', size = 1)

gg_power
```

__Мощность теста - вероятность отвергнуть $H_0$, когда верна__ $H_A$

$$Power = 1 - \beta$$

## Мощность теста

$$Power = 1 - \beta$$

Обычно считается, что хорошо, когда мощность не меньше 0.8

Т.е. что в 80% случаев мы можем найди различия заданной величины, если они есть.

```{r power-power, echo = FALSE, fig.height=3, fig.width=10.1, purl = FALSE}
```


## Анализ мощности

\columnsbegin

\column{0.5\textwidth}

*A priori*

- какой нужен объем выборки, чтобы найти различия с разумной долей уверенности?
- различия какой величины мы можем найти, если известен объем выборки?

\column{0.5\textwidth}

*Post hoc*

- смогли бы мы найти различия при помощи нашего эксперимента ($\alpha$, $n$), если бы величина эффекта была $X$?

\columnsend

# A priory анализ мощности

## A priori анализ мощности

\columnsbegin

\column{0.5\textwidth}

Что нужно

- тест
- уровень значимости
- желаемая мощность теста
- ожидаемая величина эффекта

\column{0.5\textwidth}

\pause

Что есть

- $t$-критерий
- $\alpha = 0.05$
- $Power = 0.8$
- ?

\columnsend

## Величина эффекта

$d$ Коэна (Cohen's d)


$$d = \frac{\bar x_1 - \bar x_2}{SD_{pooled}}$$

где $SD_{pooled}$ --- обобщенное стандартное отклонение

$SD_{pooled} = {\sqrt{\frac {(n _1 - 1)s_1^2 + (n _2 - 1)s_2^2 }  {n _1 + n _2 - 2} } }$


## Величина эффекта

Яков Коэн предложил делить эффекты на сильные, умеренные и слабые (Cohen, 1982)

```{r }
library(pwr)
cohen.ES(test = 't', size = 'large')
```

## Рассчет объема выборки для обнаружения эффекта известной величины

Функции для анализа мощности t-критерия:

- при одинаковых объемах групп `pwr.t.test()`
- при разных объемах групп `pwr.t2n.test()`

Какая нужна выборка, чтобы обнаружить _сильный эффект_ с вероятностью 0.8 при уровне значимости 0.05?

```{r}
pwr.t.test(n = NULL, d = 0.8, power = 0.8, sig.level = 0.01,
           type = 'two.sample', alternative = 'two.sided')
```

## Задание

Какая нужна выборка, чтобы обнаружить _слабый эффект_ с вероятностью 0.8 при уровне значимости 0.05?

Вам понадобятся функции `cohen.ES()` и `pwr.t.test()`

## Решение

\fontsize{10pt}{10pt}

```{r purl=FALSE}
cohen.ES(test = 't', size = 'small') # величина слабого эффекта по Коэну
# Какой нужен объем выборки?
pwr.t.test(n = NULL, d = 0.2, power = 0.8, sig.level = 0.05,
           type = 'two.sample', alternative = 'two.sided')
```

Для того, чтобы при помощи t-теста обнаружить слабый эффект (d = 0.2) с вероятностью 0.8 и при уровне значимости 0.05, нужно собрать выборку не меньше 394 наблюдений __в каждой__ группе.

# A priory анализ мощности по данным пилотного исследования

## Пример: Морфометрия жуков-листоедов

Измерения 43 самцов жуков-листоедов двух видов жуков из подсемейства козявок (Galerucinae) в семействе листоедов (Chrysomelidae): _Chaetocnema concinna_, _Ch. heptapotamica_.

Переменные

- fjft --- ширина первого членика первой лапки в микронах (сумма измерений для обеих лапок)
- species --- вид жуков (1=Ch. concinna, 2= Ch. heptapotamica)

Есть ли морфологические различия между видами?


```{r}
library(readxl)
flea <- read_excel(path = 'data/fleabeetles-subset.xlsx', sheet = 'dat')
```

\vfill
\tiny Фрагмент данных из работы Lubischew, A.A., 1962. On the use of discriminant functions in taxonomy. Biometrics, pp.455-477.

## Все ли правильно открылось?

```{r}
str(flea)  # Структура данных
head(flea) # Первые несколько строк файла
```

## Делаем фактором переменную, где записан вид

```{r}
flea$species <- factor(flea$species, 
                       levels = c(1, 2), 
                       labels = c('cocin', 'hept'))
```

## Знакомимся с данными

Есть ли пропущенные значения?

```{r}
colSums(is.na(flea))
```

Каковы объемы выборок? Поскольку нет пропущенных значений, можно посчитать так

```{r}
table(flea$species)
```

## Представим, что это данные пилотного исследования.

Мы хотим выяснить, сколько нужно жуков, чтобы показать, что ширина первого членика первой лапки различается у этих двух видов

График средних и стандартных отклонений

```{r fig.width = 5*0.75, out.width='5cm', fig.height=4*0.75, out.height='4cm'}
library(ggplot2)
theme_set(theme_bw())
ggplot(data = flea, aes(x = species, y = fjft)) +
  stat_summary(geom = 'pointrange', fun.data = mean_sdl) +
  labs(y = 'Ширина первого членика \nпервой лапки (мкм)', x = 'Вид')
```

## Величина эффекта по исходным данным

```{r}
library(effsize)
eff_flea <- cohen.d(d = flea$fjft, f = flea$species)
eff_flea
```

Вычислим модуль, поскольку для `pwr.t.test()` эффект должен быть положительным

```{r}
effect_size_flea <- abs(eff_flea$estimate)
```

## Задание

Рассчитайте объем выборки, чтобы показать различия размеров с вероятностью 0.8 на уровне значимости 0.05

Используйте функцию `pwr.t.test()`


## Решение

```{r purl = FALSE}
pwr_flea <- pwr.t.test(n = NULL, d = effect_size_flea, 
                       power = 0.8, sig.level = 0.05, 
                       type = 'two.sample', 
                       alternative = 'two.sided')
pwr_flea
```

\pause

- Нужна выборка из __`r ceiling(pwr_flea$n)` жуков каждого вида__, чтобы с вероятностью 0.8 обнаружить различия размеров между видами.

## Задание

Представьте, что в датасете `sleep` содержатся данные пилотного исследования.

Оцените, какой объем выборки нужно взять, чтобы показать, что число часов дополнительного сна после применения двух препаратов различается?

## Решение

\fontsize{10pt}{10pt}

```{r purl=FALSE}
eff_sleep <- cohen.d(sleep$extra, sleep$group)
effect_sleep <- abs(eff_sleep$estimate)
pwr_sleep <- pwr.t.test(n = NULL, d = effect_sleep, 
                        power = 0.8, sig.level = 0.05, 
                        type = 'two.sample', 
                        alternative = 'two.sided')
pwr_sleep
```

\fontsize{12pt}{12pt}

Нужна выборка __`r ceiling(pwr_sleep$n)` человека в каждой из групп__, чтобы с вероятностью 0.8 обнаружить различия числа часов дополнительного сна после применения двух препаратов.

# Как влиять на мощность теста?

## Чем больше объем выборки --- тем больше мощность

```{r pwr_vs_n, echo = FALSE, cache = TRUE, fig.width = 10, fig.height = 5, purl = FALSE}
# Plots of power vs. sample size etc.
# Modified after http://imdevsoftware.wordpress.com/2013/01/17/255/

# Need pwr, reshape2, ggplot2 packages
gen_pwr_vs_n <- function(d = c(0.2, 0.5, 0.8), a = c(0.05, 0.01), n = 150){
  if(!require(pwr)){install.packages('pwr');library('pwr')}
  # t-TEST
  #---------------------------------
  n <- 1:n
  t.test.power.effect<-
    as.data.frame(do.call('cbind', lapply(1:length(d),function(i){
    sapply(1:length(a),function(k){
      sapply(1:length(n), function(j){
        #       paste(d[i], n[j], a[k])
        power.t.test(n = n[j],d = d[i],sig.level = a[k],power = NULL,
                     type = 'two.sample')$power
      })
    })
  })))
  t.test.power.effect[is.na(t.test.power.effect)]<-0 # some powers couldn't be calculated, set these to zero
  # melt the data
  if(!require(reshape2)){install.packages('reshape2');library('reshape2')}
  measured <- length(d)*length(a)
  t.test.power.effect <- melt(t.test.power.effect, measure.vars = 1:measured)
  # fill the levels of n, a, and d
  nms <- expand.grid(size = n, sig.level = a, effect = d)
  t.test.power.effect <- cbind(t.test.power.effect, nms)
  # do-not need variable column
  t.test.power.effect <- t.test.power.effect[, -1]
  return(t.test.power.effect)
}

th <- theme_classic(base_size = 18) +
  theme(legend.key = element_blank(),
        axis.line.x = element_line(colour = 'black'),
        axis.line.y = element_line(colour = 'black'))

dat <-gen_pwr_vs_n(n = 150)
# factors
dat$sig.level <- factor(dat$sig.level, levels = c(0.01, 0.05), labels = c('p = 0.01', 'p = 0.05'))
dat$effect <- factor(dat$effect, levels = c(0.2, 0.3, 0.5, 0.8), labels = c('d = 0.2', 'd = 0.3', 'd = 0.5', 'd = 0.8'))

# Power increases as the sample size increases
# plot power vs n at d = 0.5, p = 0.01
pwr.size <-
  ggplot(data = dat[(dat$effect == 'd = 0.5' & dat$sig.level == 'p = 0.05'), ], aes(x = size, y = value, color = sig.level)) +
  geom_line(size = 1.5) +
  scale_colour_discrete(name = 'Уровень\nзначимости') +
  labs(x = 'Объем выборки', y = 'Мощность') +
  ggtitle('t-тест, d = 0.5') +
  th
pwr.size
```

## Чем больше уровень значимости --- тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 5, purl = FALSE}
# Power increases as the signifficance level increases
#   plot power vs n at d = 0.5, add linetype = sig.level (p = 0.01, p = 0.05)
pwr_size_apha <- ggplot(data = dat[dat$effect == 'd = 0.5', ],
                        aes(x = size, y = value, color = sig.level)) +
  geom_line(size = 1.5) +
  scale_colour_discrete(name = 'Уровень\nзначимости',
                        limits = c('p = 0.05', 'p = 0.01')) +
  labs(x = 'Объем выборки', y = 'Мощность') +
  ggtitle('t-тест, d = 0.5') +
  th
pwr_size_apha
```

## Чем больше величина различий --- тем больше мощность

```{r cache = TRUE, dependson='pwr_vs_n', echo = FALSE, warning = FALSE, fig.width = 10, fig.height = 5, purl = FALSE}
# Power increases as effect size increases
#   plot power vs n at
# add linetype = sig.level (p = 0.01, p = 0.05)
# add facets for d = 0.2, d = 0.5, d = 0.8
pwr_size_alpha_d <- ggplot(data = dat, aes(x = size, y = value, color = sig.level)) +
    geom_line(size = 1.5) + facet_wrap(~effect) +
  scale_colour_discrete(name = 'Уровень\nзначимости',
                        limits = c('p = 0.05', 'p = 0.01')) +
  labs(x = 'Объем выборки', y = 'Мощность') +
  ggtitle('t-тест') +
  th
pwr_size_alpha_d
```

## Каким образом можно повлиять на мощность теста?

- Мощность теста можно регулировать, если
    - изменить число повторностей
    - выбрать другой уровень значимости ($\alpha$)
    - определиться, какие эффекты действительно важны ($ES$)

## Take-home messages

- Чтобы не находить несуществующих эффектов, фиксируем уровень значимости
- Чтобы не пропустить значимое, рассчитываем величину эффекта, объем выборки и мощность теста
- Способность выявлять различия зависит
    - от объема выборки,
    - от уровня значимости
    - от величины эффекта

## Дополнительные ресурсы

- Quinn, Keough, 2002, pp. 164-170
- OpenIntro: Statistics
- Sokal, Rohlf, 1995, pp. 167-169.
- Zar, 1999, p. 83.
- [R Data Analysis Examples - Power Analysis for Two-group Independent sample t-test. UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/r/dae/t_test_power2.htm)
- [R Data Analysis Examples - Power Analysis for One-sample t-test.  UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/r/dae/t_test_power.htm)
- [FAQ - How is effect size used in power analysis?  UCLA: Statistical Consulting Group.](http://www.ats.ucla.edu/stat/mult_pkg/faq/general/effect_size_power/effect_size_power.htm)

